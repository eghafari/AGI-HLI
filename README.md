This report, titled "The Road Towards Artificial General Intelligence (AGI), Architectural Approaches to Reach Human-Level Intelligence (HLI)," delves into four prominent architectural paradigms proposed as potential pathways towards AGI: the Joint Embedding Predictive Architecture (JEPA), the combination of Large Language Models with Reinforcement Learning (LLMs + RL), Recurrent Generative Models (RGM), and CORTECONs(R). Achieving AGI, defined as machines with human-level cognitive abilities across a broad spectrum of intellectual tasks, necessitates exploring diverse architectural approaches. This report provides an in-depth analysis of each architecture's core principles, capabilities, strengths, weaknesses, and recent advancements, culminating in a comparative discussion of their potential to reach the ultimate goal of AGI. JEPA focuses on learning abstract representations of the world through self-supervised predictive modeling. LLMs + RL leverages the power of large language models for understanding and generating text, combined with reinforcement learning to guide behavior and decision-making. RGM employs generative modeling based on principles from statistical physics and active inference to learn complex dynamics and enable planning. Finally, CORTECONs(R) aims to achieve AGI through free energy minimization in a latent layer and integration with symbolic knowledge representations.
